{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ded74e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import psi4\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b4577f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RL(A, k, mode='rl', learning_rate=0.5, discount=0.99, max_episode=30,\n",
    "       max_pick=None,silent=False):\n",
    "    \"\"\"Returns the approximate eigenvalue and row indices for the k-sparse\n",
    "       approximate solution to the lowest eigenpair of a matrix\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : numpy.ndarray\n",
    "        The matrix to be approximately diagonalized\n",
    "    k : int\n",
    "        The maximum number of rows to retain in k-sparse apprx\n",
    "    mode: str\n",
    "        What type of diagonalization\n",
    "        'rl': use reinforcement learning\n",
    "        'apsci': a posteriori selected CI (top-k rows from full eigensolution)\n",
    "        'greedy': greedy selection of top-k rows to include\n",
    "    learning_rate: float\n",
    "        Rate of weight update during learning. Choose between (0.0,1.0]\n",
    "        Only makes sense with 'mode' == 'rl'\n",
    "    discount : float\n",
    "        How much to discount future gain in RL.\n",
    "        Only makes sense with 'mode' == 'rl'\n",
    "        Close to 0.0 : near-sighted learning\n",
    "        Close to 1.0 : far-sighted learning\n",
    "    max_episode: int\n",
    "        Maximum number of training episodes\n",
    "        Only makes sense with 'mode' == 'rl'\n",
    "    max_pick: int\n",
    "        Maximum number of external rows to consider during exploration\n",
    "        If None, defaults to maximal space possible (not efficient!)\n",
    "        Only makes sense with 'mode' == 'rl'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    E_best: float\n",
    "        Lowest eigenvalue from k-sparse approximation\n",
    "    s: array_like\n",
    "        Indices corresponding to rows for k-sparse approx solution of eigen\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    NDIM = len(A)\n",
    "\n",
    "    if max_pick is None:\n",
    "        max_pick = NDIM - k\n",
    "\n",
    "    if mode == 'rl':\n",
    "        # initialize with greedy; random init can be good choice too\n",
    "        E, idx = RL(A, k, mode='greedy')\n",
    "        #idx = np.random.choice(range(NDIM),size=k,replace=False) \n",
    "\n",
    "        # state vector is 1 if \"active\" SD, 0 otherwise\n",
    "        state = np.zeros((NDIM), dtype=np.int64)\n",
    "        state[idx] = 1  # set topk rows from initialization to \"active\"\n",
    "\n",
    "        # initial guess; note argwhere returns a 1D array, but we want 0D\n",
    "        active = np.argwhere(state == 1).reshape(-1,)\n",
    "        inactive = np.argwhere(state == 0).reshape(-1,)\n",
    "\n",
    "        # check we conserve row indices\n",
    "        assert len(active) == k\n",
    "        assert len(inactive) == NDIM - k\n",
    "\n",
    "        E, C = np.linalg.eigh(A[np.ix_(active, active)])\n",
    "        E0, C0 = E[0], C[:, 0]\n",
    "\n",
    "        # keep initial guess as our \"best\" so far\n",
    "        E_best, state_best = E0, active\n",
    "\n",
    "        # now populate the weights, renormalizing according to size\n",
    "        w = np.zeros((NDIM))\n",
    "        #w = np.random.randn(NDIM)\n",
    "\n",
    "        w[active] = np.abs(C0)  # from initial guess\n",
    "        w[active] /= np.linalg.norm(w[active])  # normalize\n",
    "        #w[active] *= len(active)/NDIM  # scale\n",
    "\n",
    "        w[inactive] = perturb(A, state)  # PT guess at weights\n",
    "        w[inactive] /= np.linalg.norm(w[inactive])  # normalize\n",
    "        #w[inactive] *= len(inactive)/NDIM  # scale\n",
    "\n",
    "        v = np.zeros_like(w)  # auxilliary weights\n",
    "\n",
    "\n",
    "        if not silent:\n",
    "            progress_bar = tqdm(range(max_episode))  # keep track of progress\n",
    "        else:\n",
    "            progress_bar = range(max_episode)  \n",
    "\n",
    "        # outer loop is training episode\n",
    "        for episode in progress_bar:\n",
    "            # current status printed out to command line\n",
    "\n",
    "            if not silent:\n",
    "                progress_bar.set_description(\"Best energy: %.6f\" % E_best)\n",
    "                #progress_bar.set_description(\"Current energy: %.6f\" % E0)\n",
    "\n",
    "            explore_rate = np.exp(-learning_rate*(episode+1))  # can tweak as desired\n",
    "\n",
    "            # set state to be top-k weights from Q-learning\n",
    "            state *= 0  # reset state vector\n",
    "\n",
    "            # sometimes top k, sometimes best state reached so far\n",
    "            if np.random.rand(1) < 0.75:\n",
    "                #print(\"top\")\n",
    "                active = np.argsort(w)[::-1][:k].reshape(-1,)\n",
    "            else:\n",
    "                #print(\"best\")\n",
    "                active = state_best\n",
    "\n",
    "            state[active] = 1\n",
    "            inactive = np.argwhere(state == 0).reshape(-1,)\n",
    "\n",
    "            # get energy from top-k\n",
    "            E, C = np.linalg.eigh(A[np.ix_(active, active)])\n",
    "            E0, C0 = E[0], C[:, 0]\n",
    "            #print(E0)\n",
    "\n",
    "            # check if top-k is globally optimal, save if it is\n",
    "            if E0 < E_best:\n",
    "                E_best = E0\n",
    "                state_best = active\n",
    "\n",
    "            # inner loop, partition into active search space\n",
    "            # I'm using their jargon -- \"selected\" and \"expanded\"\n",
    "\n",
    "            # \"selected\" are the lowest weighted rows in current selection\n",
    "            active_idx_sorted = np.argsort(w[active])  # sort asc\n",
    "            selected = np.arange(len(w))[active][active_idx_sorted]\n",
    "\n",
    "            # \"expanded\" are the highest estimated rows outside of curr sele\n",
    "            cj = perturb(A, state)  # PT guess at weights\n",
    "            inact_idx_sort = np.argsort(np.abs(cj))[::-1]  # desc\n",
    "            expanded = np.arange(len(w))[inactive][inact_idx_sort][:max_pick]\n",
    "\n",
    "            # if we don't replace anything, we can't improve, so we exit\n",
    "            total_replaced = 0\n",
    "            for j in range(max_pick):\n",
    "                assert sum(state) == k  # make sure we have consistent # row\n",
    "                is_replaced = False\n",
    "                state[expanded[j]] = 1\n",
    "                for i in range(k):\n",
    "                    state[selected[i]] = 0\n",
    "                    active = np.argwhere(state == 1).reshape(-1,)\n",
    "                    inactive = np.argwhere(state == 0).reshape(-1,)\n",
    "\n",
    "                    # check we conserve row indices\n",
    "                    assert len(active) == k\n",
    "                    assert len(inactive) == NDIM - k\n",
    "\n",
    "                    E, C = np.linalg.eigh(A[np.ix_(active, active)])\n",
    "                    Enew, Cnew = E[0], C[:, 0]\n",
    "                    if Enew < E0 * (1 - explore_rate*np.random.rand(1)):\n",
    "                        #print(\"Update\",Enew, E0)\n",
    "                        is_replaced = True\n",
    "\n",
    "                        total_replaced += 1\n",
    "\n",
    "                        # note initial state\n",
    "                        state1 = np.zeros_like(state)\n",
    "                        state1[selected] = 1\n",
    "\n",
    "                        # delete selected[i] from selected, add expanded[j]\n",
    "                        # put [expanded[j]] to make 0-D array\n",
    "                        p = selected[i]\n",
    "                        q = expanded[j]\n",
    "\n",
    "                        sele1, sele2 = np.split(selected, [i])\n",
    "                        selected = np.concatenate((sele1,\n",
    "                                                   sele2[1:],\n",
    "                                                   [expanded[j]]))\n",
    "\n",
    "                        # update state\n",
    "                        state2 = np.zeros_like(state)\n",
    "                        state2[selected] = 1\n",
    "                        active = np.argwhere(state2 == 1).reshape(-1,)\n",
    "                        inactive = np.argwhere(state2 == 0).reshape(-1,)\n",
    "\n",
    "                        # uncomment to test that selection worked as expected\n",
    "                        #E,C = np.linalg.eigh(A[np.ix_(selected,selected)])\n",
    "                        #np.testing.assert_allclose(E[0],Enew)\n",
    "\n",
    "                        # insert update here\n",
    "                        # calculate local reward\n",
    "                        R = E0 - Enew\n",
    "\n",
    "                        # note if swap was globally optimal\n",
    "                        if Enew < E_best:\n",
    "                            E_best = Enew\n",
    "                            state_best = active\n",
    "\n",
    "                        E0 = Enew\n",
    "                        C0 = Cnew\n",
    "\n",
    "                        # get best possible next move (max Q(s',a'))\n",
    "                        # a' = (p',q')\n",
    "                        pp = np.arange(len(w))[active][np.argmin(w[active])]\n",
    "                        qp = np.arange(len(w))[inactive][np.argmax(w[inactive])]\n",
    "\n",
    "                        #print(p,q,pp,qp)\n",
    "\n",
    "                        assert w[pp] == min(w[active])\n",
    "                        assert w[qp] == max(w[inactive])\n",
    "\n",
    "                        assert p not in active\n",
    "\n",
    "                        # normal weight update; delta is TD error\n",
    "                        delta = R + discount*np.dot(w,f(state2,(pp,qp))) - np.dot(w,f(state1,(p,q)))\n",
    "                        aux = np.dot(f(state1,(p,q)),v) \n",
    "\n",
    "                        # update w\n",
    "                        w += learning_rate *\\\n",
    "                             (delta*f(state1,(p,q)) - discount*aux*f(state2,(pp,qp)))\n",
    "\n",
    "                        # update v \n",
    "                        beta = np.sqrt(learning_rate) \n",
    "                        v += beta*(delta - aux)*f(state1,(p,q))\n",
    "\n",
    "                        break\n",
    "\n",
    "                    # \"p\" from \"selected\" not selected: reset it\n",
    "                    state[selected[i]] = 1\n",
    "\n",
    "                # \"q\" from \"expanded\" not selected: reset it\n",
    "                if is_replaced is False:\n",
    "                    state[expanded[j]] = 0\n",
    "\n",
    "            if total_replaced == 0:\n",
    "                break\n",
    "\n",
    "        return E_best, state_best\n",
    "\n",
    "    elif mode == 'apsci':\n",
    "\n",
    "        ## a posteriori selected CI\n",
    "        ## full matrix diagonalization first, take top-k rows/columns\n",
    "        E, C = np.linalg.eigh(A)\n",
    "        idx = np.argpartition(np.abs(C[:, 0]), -k)[-k:]  # top-k eigenvec comps\n",
    "        #\n",
    "        ## form top-k submatrix and diagonalize\n",
    "        A1 = A[np.ix_(idx, idx)]\n",
    "        E_apsci = np.linalg.eigvalsh(A1)[0]\n",
    "\n",
    "        return E_apsci, idx\n",
    "\n",
    "    elif mode == 'greedy':\n",
    "        # naive greedy selected CI\n",
    "        state = np.zeros((NDIM))\n",
    "        for i in range(k):\n",
    "            if i == 0:\n",
    "                # to begin, just take arbitrary element (not optimal)\n",
    "                state[0] = 1\n",
    "            # form top-k submatrix and diagonalize\n",
    "            active = np.argwhere(state == 1).reshape(-1,)\n",
    "            inactive = np.argwhere(state == 0).reshape(-1,)\n",
    "            A1 = A[np.ix_(active, active)]\n",
    "            E, C = np.linalg.eigh(A1)\n",
    "            E0, C0 = E[0], C[:, 0]\n",
    "\n",
    "            if i < k - 1:\n",
    "                cj = perturb(A, state)\n",
    "                cj_idx = np.argmax(np.abs(cj))\n",
    "                state[np.arange(NDIM)[inactive][cj_idx]] = 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        E_greedy = E0\n",
    "        idx = np.argwhere(state == 1)\n",
    "        assert len(idx) == k\n",
    "        return E_greedy, idx\n",
    "\n",
    "    elif mode == 'full':\n",
    "        # does full matrix diagonalization (\"exact\" result)\n",
    "        return np.linalg.eigvalsh(A)[0], None\n",
    "\n",
    "def f(state,a):\n",
    "    active = np.argwhere(state == 1).reshape(-1,) \n",
    "    vector = np.zeros_like(state)\n",
    "    p,q = a\n",
    "    assert state[p] == 1\n",
    "    assert state[q] == 0\n",
    "    vector[active] = 1\n",
    "    vector[q] =  1\n",
    "    vector[p] = -1\n",
    "    return vector/np.linalg.norm((vector))\n",
    "\n",
    "def perturb(A, state):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : numpy.ndarray\n",
    "        The matrix under consideration\n",
    "    state : array_like\n",
    "        Vector or list with '1' if index is active or '0' if inactive\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    c: array_like (dimension is number of \"0's\" in \"state\")\n",
    "        Approximate magnitude of coefficients in the inactive space as obtained\n",
    "        from (Epstein-Nesbet) perturbation theory\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    active = np.argwhere(state == 1).reshape(-1,)  # active row indices\n",
    "    inactive = np.argwhere(state == 0).reshape(-1,)  # inactive row indices\n",
    "\n",
    "    # diagonalize submatrix of active x active dimension\n",
    "    E, C = np.linalg.eigh(A[np.ix_(active, active)])\n",
    "    E0, C0 = E[0], C[:, 0]\n",
    "\n",
    "    # obtain PT approximation to importance of inactive rows (determinants)\n",
    "    a = np.minimum(1e5, np.abs(np.dot(A[np.ix_(inactive, active)], C0)))\n",
    "    b = np.maximum(1e-5, np.abs(E0-np.diagonal(A[np.ix_(inactive, inactive)])))\n",
    "    c = np.true_divide(a, b)\n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c8641c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting SCF and integral build...\n",
      "5 7 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "psi4.core.set_output_file('output.dat', False)\n",
    "\n",
    "numpy_memory = 14\n",
    "\n",
    "mol = psi4.geometry(\"\"\"\n",
    "O\n",
    "H 1 1.1\n",
    "H 1 1.1 2 104\n",
    "symmetry c1\n",
    "# \"\"\")\n",
    "#                     H-He \t                Li-Ne                   \tNa-Ar \n",
    "# cc-pVDZ   \t[2s1p] → 5 func. \t    [3s2p1d] →   14 func. \t    [4s3p1d] → 18 func.\n",
    "# cc-pVTZ   \t[3s2p1d] → 14 func. \t[4s3p2d1f] → 30 func. \t    [5s4p2d1f] → 34 func.\n",
    "# cc-pVQZ   \t[4s3p2d1f] → 30 func. \t[5s4p3d2f1g] → 55 func. \t[6s5p3d2f1g] → 59 func.\n",
    "# aug-cc-pVDZ \t[3s2p] → 9 func. \t    [4s3p2d] → 23 func.     \t[5s4p2d] → 27 func.\n",
    "# aug-cc-pVTZ \t[4s3p2d] → 23 func. \t[5s4p3d2f] → 46 func.   \t[6s5p3d2f] → 50 func.\n",
    "# aug-cc-pVQZ \t[5s4p3d2f] → 46 func. \t[6s5p4d3f2g] → 80 func. \t[7s6p4d3f2g] → 84 func. \n",
    "psi4.set_options({'basis': 'STO-6G', 'scf_type': 'pk', 'e_convergence': 1e-8, 'd_convergence': 1e-8})\n",
    "\n",
    "print('\\nStarting SCF and integral build...')\n",
    "\n",
    "scf_e, wfn = psi4.energy('SCF', return_wfn=True)\n",
    "\n",
    "C = wfn.Ca()\n",
    "\n",
    "ndocc = wfn.doccpi()[0]\n",
    "nmo = wfn.nmo()\n",
    "nvirt = nmo - ndocc\n",
    "print(ndocc,nmo,nvirt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56a4482b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "may be energy : -75.72648934089273\n",
      "\n",
      "PSI4 cisd cal: 0.198 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print(\"may be energy :\",psi4.energy('DETCI'))\n",
    "print('\\nPSI4 cisd cal: %.3f seconds.\\n' % (time.time() - t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6373c0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mints = psi4.core.MintsHelper(wfn.basisset())\n",
    "H = np.asarray(mints.ao_kinetic()) + np.asarray(mints.ao_potential())\n",
    "\n",
    "\n",
    "MO = np.asarray(mints.mo_spin_eri(C, C))\n",
    "Vee = np.asarray(mints.mo_eri(C,C,C,C))\n",
    "\n",
    "H = np.einsum('uj,vi,uv', C, C, H)\n",
    "Hone = H.copy()\n",
    "H = np.repeat(H, 2, axis=0)\n",
    "H = np.repeat(H, 2, axis=1)\n",
    "\n",
    "spin_ind = np.arange(H.shape[0], dtype=np.int64) % 2\n",
    "H *= (spin_ind.reshape(-1, 1) == spin_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95d5d422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 141 CISD Determinants...\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import comb\n",
    "nDet_S = ndocc * nvirt * 2\n",
    "nDet_D = 2 * comb(ndocc, 2) * comb(nvirt, 2) + ndocc**2 * nvirt**2\n",
    "nDet = 1 + nDet_S + nDet_D\n",
    "\n",
    "\n",
    "# nDet = comb(nmo, ndocc)**2\n",
    "\n",
    "# print(\"FCI nDet :\" ,nDet)\n",
    "\n",
    "\n",
    "from helper_CI import Determinant, HamiltonianGenerator\n",
    "from itertools import combinations\n",
    "\n",
    "print('Generating %d CISD Determinants...' % (nDet))\n",
    "\n",
    "occList = [i for i in range(ndocc)]\n",
    "\n",
    "det_ref = Determinant(alphaObtList=occList, betaObtList=occList)\n",
    "\n",
    "detList = det_ref.generateSingleAndDoubleExcitationsOfDet(nmo)\n",
    "detList.append(det_ref)\n",
    "\n",
    "Hamiltonian_generator = HamiltonianGenerator(H, MO)\n",
    "Hamiltonian_matrixCISD = Hamiltonian_generator.generateMatrix(detList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6610f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 441 Full CI Determinants...\n"
     ]
    }
   ],
   "source": [
    "nDet = comb(nmo, ndocc)**2\n",
    "print('Generating %d Full CI Determinants...' % (nDet))\n",
    "detList = []\n",
    "for alpha in combinations(range(nmo), ndocc):\n",
    "    for beta in combinations(range(nmo), ndocc):\n",
    "        detList.append(Determinant(alphaObtList=alpha, betaObtList=beta))\n",
    "\n",
    "\n",
    "t = time.time()\n",
    "Hamiltonian_generator = HamiltonianGenerator(H, MO)\n",
    "Hamiltonian_matrixFCI = Hamiltonian_generator.generateMatrix(detList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca310366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energies  0 FCI :-83.730648587054418 CISD   :-83.728855823066269\n",
      "Energies  1 FCI :-83.457159196041829 CISD   :-83.426311291330066\n",
      "Energies  2 FCI :-83.409932220195714 CISD   :-83.378450382307022\n",
      "Energies  3 FCI :-83.374575012981808 CISD   :-83.339840345742715\n",
      "Energies  4 FCI :-83.366779618225650 CISD   :-83.336968241016535\n",
      "Energies  5 FCI :-83.340405009990363 CISD   :-83.306470799506116\n",
      "Energies  6 FCI :-83.307981908309642 CISD   :-83.277003105910410\n",
      "Energies  7 FCI :-83.240599056191726 CISD   :-83.221305551089770\n",
      "Energies  8 FCI :-83.193928679946225 CISD   :-83.180092869150755\n",
      "Energies  9 FCI :-83.183946532269573 CISD   :-83.169141718254352\n",
      "0.6802721088435374\n",
      "k:     140\n",
      "NDet:  441\n",
      "Exact:   (-83.73064858705433, None)\n",
      "ap-sCI:  -83.7306485870544\n",
      "greedy:  -83.73064858705445\n"
     ]
    }
   ],
   "source": [
    "e_cisd, wavefunctions = np.linalg.eigh(Hamiltonian_matrixCISD)\n",
    "e_fci, wavefunctions = np.linalg.eigh(Hamiltonian_matrixFCI)\n",
    "for i in range(0,10):\n",
    "        print(\"Energies \",i,\"FCI :% 16.15f\"% (e_fci[i]),\"CISD   :% 16.15f\"% (e_cisd[i]))\n",
    "        \n",
    "A= Hamiltonian_matrixFCI\n",
    "from numpy import count_nonzero\n",
    "sparsity = 1.0 - ( count_nonzero(A) / float(A.size) )\n",
    "print(sparsity)\n",
    "k = 140  # sparsity\n",
    "print(\"k:    \", k)\n",
    "print(\"NDet: \", len(A))\n",
    "\n",
    "E_exact = RL(A, k, mode='full') \n",
    "print(\"Exact:  \", E_exact)\n",
    "\n",
    "E_apsci, s = RL(A, k, mode='apsci')\n",
    "print(\"ap-sCI: \", E_apsci)\n",
    "\n",
    "E_greedy, s = RL(A, k, mode='greedy')\n",
    "print(\"greedy: \", E_greedy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24c923cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best energy: -83.730649: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [05:07<00:00, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL2:     -83.73064858705445\n",
      "Energies  0 FCI :-83.730648587054418 CISD   :-83.728855823066269 RLCI :-83.730648587054418\n",
      "Energies  1 FCI :-83.457159196041829 CISD   :-83.426311291330066 RLCI :-83.457159196041829\n",
      "Energies  2 FCI :-83.409932220195714 CISD   :-83.378450382307022 RLCI :-83.409932220195714\n",
      "Energies  3 FCI :-83.374575012981808 CISD   :-83.339840345742715 RLCI :-83.374575012981808\n",
      "Energies  4 FCI :-83.366779618225650 CISD   :-83.336968241016535 RLCI :-83.366779618225650\n",
      "Energies  5 FCI :-83.340405009990363 CISD   :-83.306470799506116 RLCI :-83.340405009990363\n",
      "Energies  6 FCI :-83.307981908309642 CISD   :-83.277003105910410 RLCI :-83.307981908309642\n",
      "Energies  7 FCI :-83.240599056191726 CISD   :-83.221305551089770 RLCI :-83.240599056191726\n",
      "Energies  8 FCI :-83.193928679946225 CISD   :-83.180092869150755 RLCI :-83.193928679946225\n",
      "Energies  9 FCI :-83.183946532269573 CISD   :-83.169141718254352 RLCI :-83.183946532269573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "E_rl, s = RL(A, k, mode='rl', max_pick=None)\n",
    "print(\"RL2:    \", E_rl)\n",
    "E, C = np.linalg.eigh(A[np.ix_(s, s)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d155d12",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sapsci' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_76558/1052198043.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mEa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meigh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msapsci\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msapsci\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Energies \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"FCI :% 16.15f\"\u001b[0m\u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me_fci\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"CISD   :% 16.15f\"\u001b[0m\u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me_cisd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"RLCI :% 16.15f\"\u001b[0m\u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mEa\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sapsci' is not defined"
     ]
    }
   ],
   "source": [
    "Ea, C = np.linalg.eigh(A[np.ix_(sapsci, sapsci)])\n",
    "for i in range(0,10):\n",
    "        print(\"Energies \",i,\"FCI :% 16.15f\"% (e_fci[i]),\"CISD   :% 16.15f\"% (e_cisd[i]),\"RLCI :% 16.15f\"% (Ea[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ce05f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
