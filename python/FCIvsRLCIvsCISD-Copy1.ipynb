{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "843a227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import psi4\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f138632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RL(A, k, mode='rl', learning_rate=0.1, discount=0.99, max_episode=30,\n",
    "       max_pick=None,silent=False,ex=0):\n",
    "    \"\"\"Returns the approximate eigenvalue and row indices for the k-sparse\n",
    "       approximate solution to the lowest eigenpair of a matrix\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : numpy.ndarray\n",
    "        The matrix to be approximately diagonalized\n",
    "    k : int\n",
    "        The maximum number of rows to retain in k-sparse apprx\n",
    "    mode: str\n",
    "        What type of diagonalization\n",
    "        'rl': use reinforcement learning\n",
    "        'apsci': a posteriori selected CI (top-k rows from full eigensolution)\n",
    "        'greedy': greedy selection of top-k rows to include\n",
    "    learning_rate: float\n",
    "        Rate of weight update during learning. Choose between (0.0,1.0]\n",
    "        Only makes sense with 'mode' == 'rl'\n",
    "    discount : float\n",
    "        How much to discount future gain in RL.\n",
    "        Only makes sense with 'mode' == 'rl'\n",
    "        Close to 0.0 : near-sighted learning\n",
    "        Close to 1.0 : far-sighted learning\n",
    "    max_episode: int\n",
    "        Maximum number of training episodes\n",
    "        Only makes sense with 'mode' == 'rl'\n",
    "    max_pick: int\n",
    "        Maximum number of external rows to consider during exploration\n",
    "        If None, defaults to maximal space possible (not efficient!)\n",
    "        Only makes sense with 'mode' == 'rl'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    E_best: float\n",
    "        Lowest eigenvalue from k-sparse approximation\n",
    "    s: array_like\n",
    "        Indices corresponding to rows for k-sparse approx solution of eigen\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    NDIM = len(A)\n",
    "\n",
    "    if max_pick is None:\n",
    "        max_pick = NDIM - k\n",
    "\n",
    "    if mode == 'rl':\n",
    "        # initialize with greedy; random init can be good choice too\n",
    "        E, idx = RL(A, k, mode='greedy')\n",
    "        #idx = np.random.choice(range(NDIM),size=k,replace=False) \n",
    "\n",
    "        # state vector is 1 if \"active\" SD, 0 otherwise\n",
    "        state = np.zeros((NDIM), dtype=np.int64)\n",
    "        state[idx] = 1  # set topk rows from initialization to \"active\"\n",
    "\n",
    "        # initial guess; note argwhere returns a 1D array, but we want 0D\n",
    "        active = np.argwhere(state == 1).reshape(-1,)\n",
    "        inactive = np.argwhere(state == 0).reshape(-1,)\n",
    "\n",
    "        # check we conserve row indices\n",
    "        assert len(active) == k\n",
    "        assert len(inactive) == NDIM - k\n",
    "\n",
    "        E, C = np.linalg.eigh(A[np.ix_(active, active)])\n",
    "        E0, C0 = E[0], C[:, 0]\n",
    "\n",
    "        # keep initial guess as our \"best\" so far\n",
    "        E_best, state_best = E0, active\n",
    "\n",
    "        # now populate the weights, renormalizing according to size\n",
    "        w = np.zeros((NDIM))\n",
    "        #w = np.random.randn(NDIM)\n",
    "\n",
    "        w[active] = np.abs(C0)  # from initial guess\n",
    "        w[active] /= np.linalg.norm(w[active])  # normalize\n",
    "        #w[active] *= len(active)/NDIM  # scale\n",
    "\n",
    "        w[inactive] = perturb(A, state)  # PT guess at weights\n",
    "        w[inactive] /= np.linalg.norm(w[inactive])  # normalize\n",
    "        #w[inactive] *= len(inactive)/NDIM  # scale\n",
    "\n",
    "        v = np.zeros_like(w)  # auxilliary weights\n",
    "\n",
    "\n",
    "        if not silent:\n",
    "            progress_bar = tqdm(range(max_episode))  # keep track of progress\n",
    "        else:\n",
    "            progress_bar = range(max_episode)  \n",
    "\n",
    "        # outer loop is training episode\n",
    "        for episode in progress_bar:\n",
    "            # current status printed out to command line\n",
    "\n",
    "            if not silent:\n",
    "                progress_bar.set_description(\"Best energy: %.6f\" % E_best)\n",
    "                #progress_bar.set_description(\"Current energy: %.6f\" % E0)\n",
    "\n",
    "            explore_rate = np.exp(-learning_rate*(episode+1))  # can tweak as desired\n",
    "\n",
    "            # set state to be top-k weights from Q-learning\n",
    "            state *= 0  # reset state vector\n",
    "\n",
    "            # sometimes top k, sometimes best state reached so far\n",
    "            if np.random.rand(1) < 0.75:\n",
    "                #print(\"top\")\n",
    "                active = np.argsort(w)[::-1][:k].reshape(-1,)\n",
    "            else:\n",
    "                #print(\"best\")\n",
    "                active = state_best\n",
    "\n",
    "            state[active] = 1\n",
    "            inactive = np.argwhere(state == 0).reshape(-1,)\n",
    "\n",
    "            # get energy from top-k\n",
    "            E, C = np.linalg.eigh(A[np.ix_(active, active)])\n",
    "            E0, C0 = E[0], C[:, 0]\n",
    "            #print(E0)\n",
    "\n",
    "            # check if top-k is globally optimal, save if it is\n",
    "            if E0 < E_best:\n",
    "                E_best = E0\n",
    "                state_best = active\n",
    "\n",
    "            # inner loop, partition into active search space\n",
    "            # I'm using their jargon -- \"selected\" and \"expanded\"\n",
    "\n",
    "            # \"selected\" are the lowest weighted rows in current selection\n",
    "            active_idx_sorted = np.argsort(w[active])  # sort asc\n",
    "            selected = np.arange(len(w))[active][active_idx_sorted]\n",
    "\n",
    "            # \"expanded\" are the highest estimated rows outside of curr sele\n",
    "            cj = perturb(A, state)  # PT guess at weights\n",
    "            inact_idx_sort = np.argsort(np.abs(cj))[::-1]  # desc\n",
    "            expanded = np.arange(len(w))[inactive][inact_idx_sort][:max_pick]\n",
    "\n",
    "            # if we don't replace anything, we can't improve, so we exit\n",
    "            total_replaced = 0\n",
    "            for j in range(max_pick):\n",
    "                assert sum(state) == k  # make sure we have consistent # row\n",
    "                is_replaced = False\n",
    "                state[expanded[j]] = 1\n",
    "                for i in range(k):\n",
    "                    state[selected[i]] = 0\n",
    "                    active = np.argwhere(state == 1).reshape(-1,)\n",
    "                    inactive = np.argwhere(state == 0).reshape(-1,)\n",
    "\n",
    "                    # check we conserve row indices\n",
    "                    assert len(active) == k\n",
    "                    assert len(inactive) == NDIM - k\n",
    "\n",
    "                    E, C = np.linalg.eigh(A[np.ix_(active, active)])\n",
    "                    Enew, Cnew = E[0], C[:, 0]\n",
    "                    if Enew < E0 * (1 - explore_rate*np.random.rand(1)):\n",
    "                        #print(\"Update\",Enew, E0)\n",
    "                        is_replaced = True\n",
    "\n",
    "                        total_replaced += 1\n",
    "\n",
    "                        # note initial state\n",
    "                        state1 = np.zeros_like(state)\n",
    "                        state1[selected] = 1\n",
    "\n",
    "                        # delete selected[i] from selected, add expanded[j]\n",
    "                        # put [expanded[j]] to make 0-D array\n",
    "                        p = selected[i]\n",
    "                        q = expanded[j]\n",
    "\n",
    "                        sele1, sele2 = np.split(selected, [i])\n",
    "                        selected = np.concatenate((sele1,\n",
    "                                                   sele2[1:],\n",
    "                                                   [expanded[j]]))\n",
    "\n",
    "                        # update state\n",
    "                        state2 = np.zeros_like(state)\n",
    "                        state2[selected] = 1\n",
    "                        active = np.argwhere(state2 == 1).reshape(-1,)\n",
    "                        inactive = np.argwhere(state2 == 0).reshape(-1,)\n",
    "\n",
    "                        # uncomment to test that selection worked as expected\n",
    "                        #E,C = np.linalg.eigh(A[np.ix_(selected,selected)])\n",
    "                        #np.testing.assert_allclose(E[0],Enew)\n",
    "\n",
    "                        # insert update here\n",
    "                        # calculate local reward\n",
    "                        R = E0 - Enew\n",
    "\n",
    "                        # note if swap was globally optimal\n",
    "                        if Enew < E_best:\n",
    "                            E_best = Enew\n",
    "                            state_best = active\n",
    "\n",
    "                        E0 = Enew\n",
    "                        C0 = Cnew\n",
    "\n",
    "                        # get best possible next move (max Q(s',a'))\n",
    "                        # a' = (p',q')\n",
    "                        pp = np.arange(len(w))[active][np.argmin(w[active])]\n",
    "                        qp = np.arange(len(w))[inactive][np.argmax(w[inactive])]\n",
    "\n",
    "                        #print(p,q,pp,qp)\n",
    "\n",
    "                        assert w[pp] == min(w[active])\n",
    "                        assert w[qp] == max(w[inactive])\n",
    "\n",
    "                        assert p not in active\n",
    "\n",
    "                        # normal weight update; delta is TD error\n",
    "                        delta = R + discount*np.dot(w,f(state2,(pp,qp))) - np.dot(w,f(state1,(p,q)))\n",
    "                        aux = np.dot(f(state1,(p,q)),v) \n",
    "\n",
    "                        # update w\n",
    "                        w += learning_rate *\\\n",
    "                             (delta*f(state1,(p,q)) - discount*aux*f(state2,(pp,qp)))\n",
    "\n",
    "                        # update v \n",
    "                        beta = np.sqrt(learning_rate) \n",
    "                        v += beta*(delta - aux)*f(state1,(p,q))\n",
    "\n",
    "                        break\n",
    "\n",
    "                    # \"p\" from \"selected\" not selected: reset it\n",
    "                    state[selected[i]] = 1\n",
    "\n",
    "                # \"q\" from \"expanded\" not selected: reset it\n",
    "                if is_replaced is False:\n",
    "                    state[expanded[j]] = 0\n",
    "\n",
    "            if total_replaced == 0:\n",
    "                break\n",
    "\n",
    "        return E_best, state_best\n",
    "    if mode == 'rle':\n",
    "        # initialize with greedy; random init can be good choice too\n",
    "        E, idx = RL(A, k, mode='greedy')\n",
    "        #idx = np.random.choice(range(NDIM),size=k,replace=False) \n",
    "\n",
    "        # state vector is 1 if \"active\" SD, 0 otherwise\n",
    "        state = np.zeros((NDIM), dtype=np.int64)\n",
    "        state[idx] = 1  # set topk rows from initialization to \"active\"\n",
    "\n",
    "        # initial guess; note argwhere returns a 1D array, but we want 0D\n",
    "        active = np.argwhere(state == 1).reshape(-1,)\n",
    "        inactive = np.argwhere(state == 0).reshape(-1,)\n",
    "\n",
    "        # check we conserve row indices\n",
    "        assert len(active) == k\n",
    "        assert len(inactive) == NDIM - k\n",
    "\n",
    "        E, C = np.linalg.eigh(A[np.ix_(active, active)])\n",
    "        E0, C0 = E[ex], C[:, 0]\n",
    "\n",
    "        # keep initial guess as our \"best\" so far\n",
    "        E_best, state_best = E0, active\n",
    "\n",
    "        # now populate the weights, renormalizing according to size\n",
    "        w = np.zeros((NDIM))\n",
    "        #w = np.random.randn(NDIM)\n",
    "\n",
    "        w[active] = np.abs(C0)  # from initial guess\n",
    "        w[active] /= np.linalg.norm(w[active])  # normalize\n",
    "        #w[active] *= len(active)/NDIM  # scale\n",
    "\n",
    "        w[inactive] = perturb(A, state)  # PT guess at weights\n",
    "        w[inactive] /= np.linalg.norm(w[inactive])  # normalize\n",
    "        #w[inactive] *= len(inactive)/NDIM  # scale\n",
    "\n",
    "        v = np.zeros_like(w)  # auxilliary weights\n",
    "\n",
    "\n",
    "        if not silent:\n",
    "            progress_bar = tqdm(range(max_episode))  # keep track of progress\n",
    "        else:\n",
    "            progress_bar = range(max_episode)  \n",
    "\n",
    "        # outer loop is training episode\n",
    "        for episode in progress_bar:\n",
    "            # current status printed out to command line\n",
    "\n",
    "            if not silent:\n",
    "                progress_bar.set_description(\"Best energy: %.6f\" % E_best)\n",
    "                #progress_bar.set_description(\"Current energy: %.6f\" % E0)\n",
    "\n",
    "            explore_rate = np.exp(-learning_rate*(episode+1))  # can tweak as desired\n",
    "\n",
    "            # set state to be top-k weights from Q-learning\n",
    "            state *= 0  # reset state vector\n",
    "\n",
    "            # sometimes top k, sometimes best state reached so far\n",
    "            if np.random.rand(1) < 0.75:\n",
    "                #print(\"top\")\n",
    "                active = np.argsort(w)[::-1][:k].reshape(-1,)\n",
    "            else:\n",
    "                #print(\"best\")\n",
    "                active = state_best\n",
    "\n",
    "            state[active] = 1\n",
    "            inactive = np.argwhere(state == 0).reshape(-1,)\n",
    "\n",
    "            # get energy from top-k\n",
    "            E, C = np.linalg.eigh(A[np.ix_(active, active)])\n",
    "            E0, C0 = E[ex], C[:, 0]\n",
    "            #print(E0)\n",
    "\n",
    "            # check if top-k is globally optimal, save if it is\n",
    "            if E0 < E_best:\n",
    "                E_best = E0\n",
    "                state_best = active\n",
    "\n",
    "            # inner loop, partition into active search space\n",
    "            # I'm using their jargon -- \"selected\" and \"expanded\"\n",
    "\n",
    "            # \"selected\" are the lowest weighted rows in current selection\n",
    "            active_idx_sorted = np.argsort(w[active])  # sort asc\n",
    "            selected = np.arange(len(w))[active][active_idx_sorted]\n",
    "\n",
    "            # \"expanded\" are the highest estimated rows outside of curr sele\n",
    "            cj = perturb(A, state)  # PT guess at weights\n",
    "            inact_idx_sort = np.argsort(np.abs(cj))[::-1]  # desc\n",
    "            expanded = np.arange(len(w))[inactive][inact_idx_sort][:max_pick]\n",
    "\n",
    "            # if we don't replace anything, we can't improve, so we exit\n",
    "            total_replaced = 0\n",
    "            for j in range(max_pick):\n",
    "                assert sum(state) == k  # make sure we have consistent # row\n",
    "                is_replaced = False\n",
    "                state[expanded[j]] = 1\n",
    "                for i in range(k):\n",
    "                    state[selected[i]] = 0\n",
    "                    active = np.argwhere(state == 1).reshape(-1,)\n",
    "                    inactive = np.argwhere(state == 0).reshape(-1,)\n",
    "\n",
    "                    # check we conserve row indices\n",
    "                    assert len(active) == k\n",
    "                    assert len(inactive) == NDIM - k\n",
    "\n",
    "                    E, C = np.linalg.eigh(A[np.ix_(active, active)])\n",
    "                    Enew, Cnew = E[ex], C[:, 0]\n",
    "                    if Enew < E0 * (1 - explore_rate*np.random.rand(1)):\n",
    "                        #print(\"Update\",Enew, E0)\n",
    "                        is_replaced = True\n",
    "\n",
    "                        total_replaced += 1\n",
    "\n",
    "                        # note initial state\n",
    "                        state1 = np.zeros_like(state)\n",
    "                        state1[selected] = 1\n",
    "\n",
    "                        # delete selected[i] from selected, add expanded[j]\n",
    "                        # put [expanded[j]] to make 0-D array\n",
    "                        p = selected[i]\n",
    "                        q = expanded[j]\n",
    "\n",
    "                        sele1, sele2 = np.split(selected, [i])\n",
    "                        selected = np.concatenate((sele1,\n",
    "                                                   sele2[1:],\n",
    "                                                   [expanded[j]]))\n",
    "\n",
    "                        # update state\n",
    "                        state2 = np.zeros_like(state)\n",
    "                        state2[selected] = 1\n",
    "                        active = np.argwhere(state2 == 1).reshape(-1,)\n",
    "                        inactive = np.argwhere(state2 == 0).reshape(-1,)\n",
    "\n",
    "                        # uncomment to test that selection worked as expected\n",
    "                        #E,C = np.linalg.eigh(A[np.ix_(selected,selected)])\n",
    "                        #np.testing.assert_allclose(E[0],Enew)\n",
    "\n",
    "                        # insert update here\n",
    "                        # calculate local reward\n",
    "                        R = E0 - Enew\n",
    "\n",
    "                        # note if swap was globally optimal\n",
    "                        if Enew < E_best:\n",
    "                            E_best = Enew\n",
    "                            state_best = active\n",
    "\n",
    "                        E0 = Enew\n",
    "                        C0 = Cnew\n",
    "\n",
    "                        # get best possible next move (max Q(s',a'))\n",
    "                        # a' = (p',q')\n",
    "                        pp = np.arange(len(w))[active][np.argmin(w[active])]\n",
    "                        qp = np.arange(len(w))[inactive][np.argmax(w[inactive])]\n",
    "\n",
    "                        #print(p,q,pp,qp)\n",
    "\n",
    "                        assert w[pp] == min(w[active])\n",
    "                        assert w[qp] == max(w[inactive])\n",
    "\n",
    "                        assert p not in active\n",
    "\n",
    "                        # normal weight update; delta is TD error\n",
    "                        delta = R + discount*np.dot(w,f(state2,(pp,qp))) - np.dot(w,f(state1,(p,q)))\n",
    "                        aux = np.dot(f(state1,(p,q)),v) \n",
    "\n",
    "                        # update w\n",
    "                        w += learning_rate *\\\n",
    "                             (delta*f(state1,(p,q)) - discount*aux*f(state2,(pp,qp)))\n",
    "\n",
    "                        # update v \n",
    "                        beta = np.sqrt(learning_rate) \n",
    "                        v += beta*(delta - aux)*f(state1,(p,q))\n",
    "\n",
    "                        break\n",
    "\n",
    "                    # \"p\" from \"selected\" not selected: reset it\n",
    "                    state[selected[i]] = 1\n",
    "\n",
    "                # \"q\" from \"expanded\" not selected: reset it\n",
    "                if is_replaced is False:\n",
    "                    state[expanded[j]] = 0\n",
    "\n",
    "            if total_replaced == 0:\n",
    "                break\n",
    "\n",
    "        return E_best, state_best\n",
    "    if mode == 'rleg':\n",
    "        # initialize with greedy; random init can be good choice too\n",
    "        E, idx = RL(A, k, mode='greedy')\n",
    "        #idx = np.random.choice(range(NDIM),size=k,replace=False) \n",
    "\n",
    "        # state vector is 1 if \"active\" SD, 0 otherwise\n",
    "        state = np.zeros((NDIM), dtype=np.int64)\n",
    "        state[idx] = 1  # set topk rows from initialization to \"active\"\n",
    "\n",
    "        # initial guess; note argwhere returns a 1D array, but we want 0D\n",
    "        active = np.argwhere(state == 1).reshape(-1,)\n",
    "        inactive = np.argwhere(state == 0).reshape(-1,)\n",
    "\n",
    "        # check we conserve row indices\n",
    "        assert len(active) == k\n",
    "        assert len(inactive) == NDIM - k\n",
    "\n",
    "        E, C = np.linalg.eigh(A[np.ix_(active, active)])\n",
    "        E0, C0 = E[ex], C[:, 0]\n",
    "        E0 = 20*E[0]+5*E[1]+2.5*E[2]+1.25*E[3]+0.65*E[4]+0.3*E[5]\n",
    "\n",
    "        # keep initial guess as our \"best\" so far\n",
    "        E_best, state_best = E0, active\n",
    "\n",
    "        # now populate the weights, renormalizing according to size\n",
    "        w = np.zeros((NDIM))\n",
    "        #w = np.random.randn(NDIM)\n",
    "\n",
    "        w[active] = np.abs(C0)  # from initial guess\n",
    "        w[active] /= np.linalg.norm(w[active])  # normalize\n",
    "        #w[active] *= len(active)/NDIM  # scale\n",
    "\n",
    "        w[inactive] = perturb(A, state)  # PT guess at weights\n",
    "        w[inactive] /= np.linalg.norm(w[inactive])  # normalize\n",
    "        #w[inactive] *= len(inactive)/NDIM  # scale\n",
    "\n",
    "        v = np.zeros_like(w)  # auxilliary weights\n",
    "\n",
    "\n",
    "        if not silent:\n",
    "            progress_bar = tqdm(range(max_episode))  # keep track of progress\n",
    "        else:\n",
    "            progress_bar = range(max_episode)  \n",
    "\n",
    "        # outer loop is training episode\n",
    "        for episode in progress_bar:\n",
    "            # current status printed out to command line\n",
    "\n",
    "            if not silent:\n",
    "                progress_bar.set_description(\"Best energy: %.6f\" % E_best)\n",
    "                #progress_bar.set_description(\"Current energy: %.6f\" % E0)\n",
    "\n",
    "            explore_rate = np.exp(-learning_rate*(episode+1))  # can tweak as desired\n",
    "\n",
    "            # set state to be top-k weights from Q-learning\n",
    "            state *= 0  # reset state vector\n",
    "\n",
    "            # sometimes top k, sometimes best state reached so far\n",
    "            if np.random.rand(1) < 0.75:\n",
    "                #print(\"top\")\n",
    "                active = np.argsort(w)[::-1][:k].reshape(-1,)\n",
    "            else:\n",
    "                #print(\"best\")\n",
    "                active = state_best\n",
    "\n",
    "            state[active] = 1\n",
    "            inactive = np.argwhere(state == 0).reshape(-1,)\n",
    "\n",
    "            # get energy from top-k\n",
    "            E, C = np.linalg.eigh(A[np.ix_(active, active)])\n",
    "            E0, C0 = E[ex], C[:, 0]\n",
    "            E0=20*E[0]+5*E[1]+2.5*E[2]+1.25*E[3]+0.65*E[4]+0.3*E[5]\n",
    "            #print(E0)\n",
    "\n",
    "            # check if top-k is globally optimal, save if it is\n",
    "            if E0 < E_best:\n",
    "                E_best = E0\n",
    "                state_best = active\n",
    "\n",
    "            # inner loop, partition into active search space\n",
    "            # I'm using their jargon -- \"selected\" and \"expanded\"\n",
    "\n",
    "            # \"selected\" are the lowest weighted rows in current selection\n",
    "            active_idx_sorted = np.argsort(w[active])  # sort asc\n",
    "            selected = np.arange(len(w))[active][active_idx_sorted]\n",
    "\n",
    "            # \"expanded\" are the highest estimated rows outside of curr sele\n",
    "            cj = perturb(A, state)  # PT guess at weights\n",
    "            inact_idx_sort = np.argsort(np.abs(cj))[::-1]  # desc\n",
    "            expanded = np.arange(len(w))[inactive][inact_idx_sort][:max_pick]\n",
    "\n",
    "            # if we don't replace anything, we can't improve, so we exit\n",
    "            total_replaced = 0\n",
    "            for j in range(max_pick):\n",
    "                assert sum(state) == k  # make sure we have consistent # row\n",
    "                is_replaced = False\n",
    "                state[expanded[j]] = 1\n",
    "                for i in range(k):\n",
    "                    state[selected[i]] = 0\n",
    "                    active = np.argwhere(state == 1).reshape(-1,)\n",
    "                    inactive = np.argwhere(state == 0).reshape(-1,)\n",
    "\n",
    "                    # check we conserve row indices\n",
    "                    assert len(active) == k\n",
    "                    assert len(inactive) == NDIM - k\n",
    "\n",
    "                    E, C = np.linalg.eigh(A[np.ix_(active, active)])\n",
    "                    Enew, Cnew = E[ex], C[:, 0]\n",
    "                    Enew= 20*E[0]+5*E[1]+2.5*E[2]+1.25*E[3]+0.65*E[4]+0.3*E[5]\n",
    "                    if Enew < E0 * (1 - explore_rate*np.random.rand(1)):\n",
    "                        #print(\"Update\",Enew, E0)\n",
    "                        is_replaced = True\n",
    "\n",
    "                        total_replaced += 1\n",
    "\n",
    "                        # note initial state\n",
    "                        state1 = np.zeros_like(state)\n",
    "                        state1[selected] = 1\n",
    "\n",
    "                        # delete selected[i] from selected, add expanded[j]\n",
    "                        # put [expanded[j]] to make 0-D array\n",
    "                        p = selected[i]\n",
    "                        q = expanded[j]\n",
    "\n",
    "                        sele1, sele2 = np.split(selected, [i])\n",
    "                        selected = np.concatenate((sele1,\n",
    "                                                   sele2[1:],\n",
    "                                                   [expanded[j]]))\n",
    "\n",
    "                        # update state\n",
    "                        state2 = np.zeros_like(state)\n",
    "                        state2[selected] = 1\n",
    "                        active = np.argwhere(state2 == 1).reshape(-1,)\n",
    "                        inactive = np.argwhere(state2 == 0).reshape(-1,)\n",
    "\n",
    "                        # uncomment to test that selection worked as expected\n",
    "                        #E,C = np.linalg.eigh(A[np.ix_(selected,selected)])\n",
    "                        #np.testing.assert_allclose(E[0],Enew)\n",
    "\n",
    "                        # insert update here\n",
    "                        # calculate local reward\n",
    "                        R = E0 - Enew\n",
    "\n",
    "                        # note if swap was globally optimal\n",
    "                        if Enew < E_best:\n",
    "                            E_best = Enew\n",
    "                            state_best = active\n",
    "\n",
    "                        E0 = Enew\n",
    "                        C0 = Cnew\n",
    "\n",
    "                        # get best possible next move (max Q(s',a'))\n",
    "                        # a' = (p',q')\n",
    "                        pp = np.arange(len(w))[active][np.argmin(w[active])]\n",
    "                        qp = np.arange(len(w))[inactive][np.argmax(w[inactive])]\n",
    "\n",
    "                        #print(p,q,pp,qp)\n",
    "\n",
    "                        assert w[pp] == min(w[active])\n",
    "                        assert w[qp] == max(w[inactive])\n",
    "\n",
    "                        assert p not in active\n",
    "\n",
    "                        # normal weight update; delta is TD error\n",
    "                        delta = R + discount*np.dot(w,f(state2,(pp,qp))) - np.dot(w,f(state1,(p,q)))\n",
    "                        aux = np.dot(f(state1,(p,q)),v) \n",
    "\n",
    "                        # update w\n",
    "                        w += learning_rate *\\\n",
    "                             (delta*f(state1,(p,q)) - discount*aux*f(state2,(pp,qp)))\n",
    "\n",
    "                        # update v \n",
    "                        beta = np.sqrt(learning_rate) \n",
    "                        v += beta*(delta - aux)*f(state1,(p,q))\n",
    "\n",
    "                        break\n",
    "\n",
    "                    # \"p\" from \"selected\" not selected: reset it\n",
    "                    state[selected[i]] = 1\n",
    "\n",
    "                # \"q\" from \"expanded\" not selected: reset it\n",
    "                if is_replaced is False:\n",
    "                    state[expanded[j]] = 0\n",
    "\n",
    "            if total_replaced == 0:\n",
    "                break\n",
    "\n",
    "        return E_best, state_best\n",
    "    elif mode == 'apsci':\n",
    "\n",
    "        ## a posteriori selected CI\n",
    "        ## full matrix diagonalization first, take top-k rows/columns\n",
    "        E, C = np.linalg.eigh(A)\n",
    "        idx = np.argpartition(np.abs(C[:, 0]), -k)[-k:]  # top-k eigenvec comps\n",
    "        #\n",
    "        ## form top-k submatrix and diagonalize\n",
    "        A1 = A[np.ix_(idx, idx)]\n",
    "        E_apsci = np.linalg.eigvalsh(A1)[0]\n",
    "\n",
    "        return E_apsci, idx\n",
    "\n",
    "    elif mode == 'greedy':\n",
    "        # naive greedy selected CI\n",
    "        state = np.zeros((NDIM))\n",
    "        for i in range(k):\n",
    "            if i == 0:\n",
    "                # to begin, just take arbitrary element (not optimal)\n",
    "                state[0] = 1\n",
    "            # form top-k submatrix and diagonalize\n",
    "            active = np.argwhere(state == 1).reshape(-1,)\n",
    "            inactive = np.argwhere(state == 0).reshape(-1,)\n",
    "            A1 = A[np.ix_(active, active)]\n",
    "            E, C = np.linalg.eigh(A1)\n",
    "            E0, C0 = E[0], C[:, 0]\n",
    "\n",
    "            if i < k - 1:\n",
    "                cj = perturb(A, state)\n",
    "                cj_idx = np.argmax(np.abs(cj))\n",
    "                state[np.arange(NDIM)[inactive][cj_idx]] = 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        E_greedy = E0\n",
    "        idx = np.argwhere(state == 1)\n",
    "        assert len(idx) == k\n",
    "        return E_greedy, idx\n",
    "\n",
    "    elif mode == 'full':\n",
    "        # does full matrix diagonalization (\"exact\" result)\n",
    "        return np.linalg.eigvalsh(A)[0], None\n",
    "\n",
    "def f(state,a):\n",
    "    active = np.argwhere(state == 1).reshape(-1,) \n",
    "    vector = np.zeros_like(state)\n",
    "    p,q = a\n",
    "    assert state[p] == 1\n",
    "    assert state[q] == 0\n",
    "    vector[active] = 1\n",
    "    vector[q] =  1\n",
    "    vector[p] = -1\n",
    "    return vector/np.linalg.norm((vector))\n",
    "\n",
    "def perturb(A, state):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : numpy.ndarray\n",
    "        The matrix under consideration\n",
    "    state : array_like\n",
    "        Vector or list with '1' if index is active or '0' if inactive\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    c: array_like (dimension is number of \"0's\" in \"state\")\n",
    "        Approximate magnitude of coefficients in the inactive space as obtained\n",
    "        from (Epstein-Nesbet) perturbation theory\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    active = np.argwhere(state == 1).reshape(-1,)  # active row indices\n",
    "    inactive = np.argwhere(state == 0).reshape(-1,)  # inactive row indices\n",
    "\n",
    "    # diagonalize submatrix of active x active dimension\n",
    "    E, C = np.linalg.eigh(A[np.ix_(active, active)])\n",
    "    E0, C0 = E[0], C[:, 0]\n",
    "\n",
    "    # obtain PT approximation to importance of inactive rows (determinants)\n",
    "    a = np.minimum(1e5, np.abs(np.dot(A[np.ix_(inactive, active)], C0)))\n",
    "    b = np.maximum(1e-5, np.abs(E0-np.diagonal(A[np.ix_(inactive, inactive)])))\n",
    "    c = np.true_divide(a, b)\n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "697cb471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting SCF and integral build...\n",
      "4 14 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "psi4.core.set_output_file('output.dat', False)\n",
    "\n",
    "numpy_memory = 14\n",
    "\n",
    "mol = psi4.geometry(\"\"\"\n",
    "O\n",
    "symmetry c1\n",
    "\n",
    "\"\"\")\n",
    "#                     H-He \t                Li-Ne                   \tNa-Ar \n",
    "# cc-pVDZ   \t[2s1p] → 5 func. \t    [3s2p1d] →   14 func. \t    [4s3p1d] → 18 func.\n",
    "# cc-pVTZ   \t[3s2p1d] → 14 func. \t[4s3p2d1f] → 30 func. \t    [5s4p2d1f] → 34 func.\n",
    "# cc-pVQZ   \t[4s3p2d1f] → 30 func. \t[5s4p3d2f1g] → 55 func. \t[6s5p3d2f1g] → 59 func.\n",
    "# aug-cc-pVDZ \t[3s2p] → 9 func. \t    [4s3p2d] → 23 func.     \t[5s4p2d] → 27 func.\n",
    "# aug-cc-pVTZ \t[4s3p2d] → 23 func. \t[5s4p3d2f] → 46 func.   \t[6s5p3d2f] → 50 func.\n",
    "# aug-cc-pVQZ \t[5s4p3d2f] → 46 func. \t[6s5p4d3f2g] → 80 func. \t[7s6p4d3f2g] → 84 func. \n",
    "psi4.set_options({'basis': 'cc-pVDZ', 'scf_type': 'pk', 'e_convergence': 1e-8, 'd_convergence': 1e-8})\n",
    "\n",
    "print('\\nStarting SCF and integral build...')\n",
    "\n",
    "scf_e, wfn = psi4.energy('SCF', return_wfn=True)\n",
    "\n",
    "C = wfn.Ca()\n",
    "\n",
    "ndocc = wfn.doccpi()[0]\n",
    "nmo = wfn.nmo()\n",
    "nvirt = nmo - ndocc\n",
    "print(ndocc,nmo,nvirt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2ed633a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "may be energy : -74.81298981780854\n",
      "\n",
      "PSI4 cisd cal: 0.866 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print(\"may be energy :\",psi4.energy('DETCI'))\n",
    "print('\\nPSI4 cisd cal: %.3f seconds.\\n' % (time.time() - t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7a0b427",
   "metadata": {},
   "outputs": [],
   "source": [
    "mints = psi4.core.MintsHelper(wfn.basisset())\n",
    "H = np.asarray(mints.ao_kinetic()) + np.asarray(mints.ao_potential())\n",
    "\n",
    "\n",
    "MO = np.asarray(mints.mo_spin_eri(C, C))\n",
    "Vee = np.asarray(mints.mo_eri(C,C,C,C))\n",
    "\n",
    "H = np.einsum('uj,vi,uv', C, C, H)\n",
    "Hone = H.copy()\n",
    "H = np.repeat(H, 2, axis=0)\n",
    "H = np.repeat(H, 2, axis=1)\n",
    "\n",
    "spin_ind = np.arange(H.shape[0], dtype=np.int64) % 2\n",
    "H *= (spin_ind.reshape(-1, 1) == spin_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57c99f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 2221 CISD Determinants...\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import comb\n",
    "nDet_S = ndocc * nvirt * 2\n",
    "nDet_D = 2 * comb(ndocc, 2) * comb(nvirt, 2) + ndocc**2 * nvirt**2\n",
    "nDet = 1 + nDet_S + nDet_D\n",
    "\n",
    "\n",
    "# nDet = comb(nmo, ndocc)**2\n",
    "\n",
    "# print(\"FCI nDet :\" ,nDet)\n",
    "\n",
    "\n",
    "from helper_CI import Determinant, HamiltonianGenerator\n",
    "from itertools import combinations\n",
    "\n",
    "print('Generating %d CISD Determinants...' % (nDet))\n",
    "\n",
    "occList = [i for i in range(ndocc)]\n",
    "\n",
    "det_ref = Determinant(alphaObtList=occList, betaObtList=occList)\n",
    "\n",
    "detList = det_ref.generateSingleAndDoubleExcitationsOfDet(nmo)\n",
    "detList.append(det_ref)\n",
    "\n",
    "Hamiltonian_generator = HamiltonianGenerator(H, MO)\n",
    "Hamiltonian_matrixCISD = Hamiltonian_generator.generateMatrix(detList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "286aa027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nDet = comb(nmo, ndocc)**2\n",
    "# print('Generating %d Full CI Determinants...' % (nDet))\n",
    "# detList = []\n",
    "# for alpha in combinations(range(nmo), ndocc):\n",
    "#     for beta in combinations(range(nmo), ndocc):\n",
    "#         detList.append(Determinant(alphaObtList=alpha, betaObtList=beta))\n",
    "\n",
    "\n",
    "# t = time.time()\n",
    "# Hamiltonian_generator = HamiltonianGenerator(H, MO)\n",
    "# Hamiltonian_matrixFCI = Hamiltonian_generator.generateMatrix(detList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51115751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "843.2514452996804\n",
      "k:     845\n",
      "NDet:  2221\n",
      "Exact:   (-74.84223467819504, None)\n",
      "ap-sCI:  -74.84223467819504\n",
      "greedy:  -74.8419853278891\n"
     ]
    }
   ],
   "source": [
    "e_cisd, wavefunctions = np.linalg.eigh(Hamiltonian_matrixCISD)\n",
    "# e_fci, wavefunctions = np.linalg.eigh(Hamiltonian_matrixFCI)\n",
    "# for i in range(0,10):\n",
    "#         print(\"Energies \",i,\"FCI :% 16.15f\"% (e_fci[i]),\"CISD   :% 16.15f\"% (e_cisd[i]))\n",
    "        \n",
    "A= Hamiltonian_matrixCISD\n",
    "from numpy import count_nonzero\n",
    "sparsity = len(A)*np.sqrt( count_nonzero(A) / float(A.size) )\n",
    "print(sparsity)\n",
    "k = 845  # sparsity\n",
    "print(\"k:    \", k)\n",
    "print(\"NDet: \", len(A))\n",
    "\n",
    "E_exact = RL(A, k, mode='full') \n",
    "print(\"Exact:  \", E_exact)\n",
    "\n",
    "E_apsci, sapsci = RL(A, k, mode='apsci')\n",
    "print(\"ap-sCI: \", E_apsci)\n",
    "\n",
    "E_greedy, sgreedy = RL(A, k, mode='greedy')\n",
    "print(\"greedy: \", E_greedy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27869825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 CISD   :-74.842234678195027 ap-sCI :-74.842234678195041 Greedy :-74.841985327889105\n",
      "1 CISD   :-74.842234678194998 ap-sCI :-74.842234678194984 Greedy :-74.794797992101351\n",
      "2 CISD   :-74.816507361171588 ap-sCI :-74.807809801454368 Greedy :-74.766544743833563\n",
      "3 CISD   :-74.812989817820480 ap-sCI :-74.791555107181736 Greedy :-74.725843378829481\n",
      "4 CISD   :-74.767303682077866 ap-sCI :-74.767303682077781 Greedy :-73.819251036850119\n",
      "5 CISD   :-74.767303682077767 ap-sCI :-74.767303682077781 Greedy :-73.745208743320816\n",
      "6 CISD   :-74.735401034467813 ap-sCI :-74.726869687266230 Greedy :-73.726601351715217\n",
      "7 CISD   :-74.735401034467785 ap-sCI :-74.721743051210197 Greedy :-73.701494181295089\n",
      "8 CISD   :-74.680531216947230 ap-sCI :-74.660685655751521 Greedy :-73.698767942099380\n",
      "9 CISD   :-74.238985840820504 ap-sCI :-74.208329717790846 Greedy :-73.638641200711987\n"
     ]
    }
   ],
   "source": [
    "s= np.array([x[0] for x in sgreedy[:]])\n",
    "# print(s)\n",
    "E, C = np.linalg.eigh(A[np.ix_(sapsci, sapsci)])\n",
    "Eg, C = np.linalg.eigh(A[np.ix_(s, s)])\n",
    "for i in range(0,10):\n",
    "#         print(i,\"FCI :% 16.15f\"% (e_fci[i]),\"CISD   :% 16.15f\"% (e_cisd[i]),\"ap-sCI :% 16.15f\"% (E[i]),\"Greedy :% 16.15f\"% (Eg[i]))\n",
    "    print(i,\"CISD   :% 16.15f\"% (e_cisd[i]),\"ap-sCI :% 16.15f\"% (E[i]),\"Greedy :% 16.15f\"% (Eg[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3725d046",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_rl, sg = RL(A, k, mode='rleg', max_pick=100)\n",
    "# print(\"RL2:    \", E_rl)\n",
    "\n",
    "# E_rle, se1 = RL(A, k, mode='rle', max_pick=None,ex=1)\n",
    "# E_rle, se2 = RL(A, k, mode='rle', max_pick=None,ex=2)\n",
    "# E_rle, se3 = RL(A, k, mode='rle', max_pick=None,ex=3)\n",
    "# E_rle, se4 = RL(A, k, mode='rle', max_pick=None,ex=4)\n",
    "# E_rle, se5 = RL(A, k, mode='rle', max_pick=None,ex=5)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4342ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(sg),len(se1),len(se2),len(se3),len(se4),len(se5))\n",
    "# print(se)\n",
    "\n",
    "# t = np.unique(np.concatenate((sg,se1,se2,se3,se4,se5),0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d6aeb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(sg)\n",
    "# print(se)\n",
    "# print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c741f7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(len(sg),len(t))\n",
    "E, C = np.linalg.eigh(A[np.ix_(sg, sg)])\n",
    "for i in range(0,10):\n",
    "#         print(\"Energies \",i,\"FCI :% 16.15f\"% (e_fci[i]),\"CISD   :% 16.15f\"% (e_cisd[i]),\"RLCI :% 16.15f\"% (E[i]))\n",
    "        print(\"Energies \",i,\"CISD   :% 16.15f\"% (e_cisd[i]),\"RLCI :% 16.15f\"% (E[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf44ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
